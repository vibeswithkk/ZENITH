{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Zenith Phase 5 - Tensor Core WMMA Testing\n",
                "\n",
                "**Target GPU**: NVIDIA T4 (65 TFLOPS FP16)\n",
                "\n",
                "**Goal**: Verify Tensor Cores are working correctly"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 1: Check GPU\n",
                "!nvidia-smi"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 2: Install CuPy for GPU operations\n",
                "!pip install cupy-cuda11x -q"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 3: NumPy Baseline (CPU)\n",
                "import numpy as np\n",
                "import time\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"NUMPY BASELINE (CPU)\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "sizes = [(1024, 1024, 1024), (2048, 2048, 2048), (4096, 4096, 4096)]\n",
                "\n",
                "for m, n, k in sizes:\n",
                "    a = np.random.randn(m, k).astype(np.float32)\n",
                "    b = np.random.randn(k, n).astype(np.float32)\n",
                "    \n",
                "    _ = a @ b  # Warmup\n",
                "    \n",
                "    times = []\n",
                "    for _ in range(5):\n",
                "        start = time.perf_counter()\n",
                "        c = a @ b\n",
                "        times.append((time.perf_counter() - start) * 1000)\n",
                "    \n",
                "    mean_ms = np.mean(times)\n",
                "    tflops = (2 * m * n * k) / (mean_ms / 1000) / 1e12\n",
                "    print(f\"{m}x{n}x{k}: {mean_ms:.1f} ms, {tflops:.3f} TFLOPS\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 4: cuBLAS FP32 (GPU)\n",
                "import cupy as cp\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"CUBLAS FP32 (GPU)\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for m, n, k in sizes:\n",
                "    a = cp.random.randn(m, k).astype(cp.float32)\n",
                "    b = cp.random.randn(k, n).astype(cp.float32)\n",
                "    \n",
                "    cp.cuda.Stream.null.synchronize()\n",
                "    _ = a @ b\n",
                "    cp.cuda.Stream.null.synchronize()\n",
                "    \n",
                "    times = []\n",
                "    for _ in range(20):\n",
                "        cp.cuda.Stream.null.synchronize()\n",
                "        start = time.perf_counter()\n",
                "        c = a @ b\n",
                "        cp.cuda.Stream.null.synchronize()\n",
                "        times.append((time.perf_counter() - start) * 1000)\n",
                "    \n",
                "    mean_ms = np.mean(times)\n",
                "    tflops = (2 * m * n * k) / (mean_ms / 1000) / 1e12\n",
                "    print(f\"{m}x{n}x{k}: {mean_ms:.2f} ms, {tflops:.2f} TFLOPS\")\n",
                "\n",
                "print(\"\\nT4 FP32 Theoretical: 8.1 TFLOPS\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 5: FP16 TENSOR CORE (GPU) - Main Test\n",
                "print(\"=\" * 50)\n",
                "print(\"FP16 TENSOR CORE (GPU)\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for m, n, k in sizes:\n",
                "    a = cp.random.randn(m, k).astype(cp.float16)\n",
                "    b = cp.random.randn(k, n).astype(cp.float16)\n",
                "    \n",
                "    cp.cuda.Stream.null.synchronize()\n",
                "    _ = a @ b\n",
                "    cp.cuda.Stream.null.synchronize()\n",
                "    \n",
                "    times = []\n",
                "    for _ in range(20):\n",
                "        cp.cuda.Stream.null.synchronize()\n",
                "        start = time.perf_counter()\n",
                "        c = a @ b\n",
                "        cp.cuda.Stream.null.synchronize()\n",
                "        times.append((time.perf_counter() - start) * 1000)\n",
                "    \n",
                "    mean_ms = np.mean(times)\n",
                "    tflops = (2 * m * n * k) / (mean_ms / 1000) / 1e12\n",
                "    efficiency = (tflops / 65) * 100\n",
                "    print(f\"{m}x{n}x{k}: {mean_ms:.2f} ms, {tflops:.1f} TFLOPS ({efficiency:.0f}% efficiency)\")\n",
                "\n",
                "print(\"\\nT4 FP16 Theoretical: 65 TFLOPS\")\n",
                "print(\"Target: >40 TFLOPS (>60% efficiency)\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cell 6: Summary\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"ZENITH PHASE 5 VERIFICATION\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\")\n",
                "print(\"If FP16 TFLOPS > 40: Tensor Cores WORKING\")\n",
                "print(\"If FP16 TFLOPS < 20: Tensor Cores NOT USED\")\n",
                "print(\"\")\n",
                "print(\"Report these results to continue to Phase 6.\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}