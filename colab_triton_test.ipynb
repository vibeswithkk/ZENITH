{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zenith Testing Notebook\n",
                "\n",
                "Testing Triton Integration, Load Testing, dan QAT pada Google Colab.\n",
                "\n",
                "**Features Tested:**\n",
                "- Triton Client (Mock)\n",
                "- Load Testing\n",
                "- QAT (Quantization-Aware Training)\n",
                "- Benchmark Utilities"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "!git clone https://github.com/vibeswithkk/ZENITH.git\n",
                "%cd ZENITH"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q numpy pytest requests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "import numpy as np\n",
                "print(f\"NumPy version: {np.__version__}\")\n",
                "print(\"Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Triton Client Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from zenith.serving.triton_client import (\n",
                "    MockTritonClient,\n",
                "    InferenceInput,\n",
                "    ModelMetadata\n",
                ")\n",
                "\n",
                "# Create mock client\n",
                "client = MockTritonClient(\"localhost:8000\")\n",
                "\n",
                "# Register a test model\n",
                "def model_handler(inputs):\n",
                "    \"\"\"Simple model that doubles the input.\"\"\"\n",
                "    return {\"output\": inputs[0].data * 2}\n",
                "\n",
                "client.register_model(\n",
                "    \"test_model\",\n",
                "    metadata=ModelMetadata(name=\"test_model\", platform=\"python\", versions=[\"1\"]),\n",
                "    handler=model_handler\n",
                ")\n",
                "\n",
                "# Test health check\n",
                "print(f\"Server Live: {client.is_server_live()}\")\n",
                "print(f\"Server Ready: {client.is_server_ready()}\")\n",
                "print(f\"Model Ready: {client.is_model_ready('test_model')}\")\n",
                "print(f\"Models: {client.list_models()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test inference\n",
                "input_data = np.array([[1.0, 2.0, 3.0]], dtype=np.float32)\n",
                "inputs = [InferenceInput(name=\"input\", data=input_data)]\n",
                "\n",
                "result = client.infer(\"test_model\", inputs)\n",
                "\n",
                "print(f\"Success: {result.success}\")\n",
                "print(f\"Model: {result.model_name}\")\n",
                "print(f\"Latency: {result.latency_ms:.3f} ms\")\n",
                "print(f\"Input: {input_data}\")\n",
                "print(f\"Output: {result.get_output('output')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tests.integration.triton_load_test import run_mock_load_test\n",
                "\n",
                "# Run load test with 100 requests\n",
                "result = run_mock_load_test(\n",
                "    model_name=\"load_test_model\",\n",
                "    num_requests=100,\n",
                "    concurrent_workers=10,\n",
                "    verbose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run higher concurrency test\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"HIGH CONCURRENCY TEST\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "result = run_mock_load_test(\n",
                "    model_name=\"high_concurrency_model\",\n",
                "    num_requests=500,\n",
                "    concurrent_workers=50,\n",
                "    verbose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. QAT (Quantization-Aware Training) Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from zenith.optimization.qat import (\n",
                "    FakeQuantize,\n",
                "    QATConfig,\n",
                "    fold_bn_into_conv\n",
                ")\n",
                "\n",
                "# Test FakeQuantize\n",
                "fq = FakeQuantize(num_bits=8, symmetric=True)\n",
                "\n",
                "# Generate test data\n",
                "data = np.random.randn(1000).astype(np.float32) * 3\n",
                "\n",
                "# Observe data (calibration)\n",
                "fq.observe(data)\n",
                "\n",
                "# Apply fake quantization\n",
                "quantized = fq.forward(data)\n",
                "\n",
                "# Calculate error\n",
                "error = np.abs(data - quantized)\n",
                "print(f\"Max Error: {np.max(error):.6f}\")\n",
                "print(f\"Mean Error: {np.mean(error):.6f}\")\n",
                "print(f\"Scale: {fq.scale}\")\n",
                "print(f\"Zero Point: {fq.zero_point}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test per-channel quantization\n",
                "fq_perchannel = FakeQuantize(num_bits=8, symmetric=True, per_channel=True, channel_axis=0)\n",
                "\n",
                "# Create data with different ranges per channel\n",
                "channel_data = np.stack([\n",
                "    np.random.randn(100).astype(np.float32) * 1,   # Scale 1\n",
                "    np.random.randn(100).astype(np.float32) * 10,  # Scale 10\n",
                "    np.random.randn(100).astype(np.float32) * 100  # Scale 100\n",
                "], axis=0)\n",
                "\n",
                "fq_perchannel.observe(channel_data)\n",
                "quantized = fq_perchannel.forward(channel_data)\n",
                "\n",
                "print(f\"Per-channel scales: {fq_perchannel.scale}\")\n",
                "print(f\"Channel 0 error: {np.mean(np.abs(channel_data[0] - quantized[0])):.6f}\")\n",
                "print(f\"Channel 1 error: {np.mean(np.abs(channel_data[1] - quantized[1])):.6f}\")\n",
                "print(f\"Channel 2 error: {np.mean(np.abs(channel_data[2] - quantized[2])):.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test BatchNorm Folding\n",
                "print(\"\\nBatch Normalization Folding Test:\")\n",
                "\n",
                "# Create conv weights\n",
                "weight = np.random.randn(4, 3, 3, 3).astype(np.float32)\n",
                "bias = np.random.randn(4).astype(np.float32)\n",
                "\n",
                "# Create BN parameters\n",
                "bn_mean = np.random.randn(4).astype(np.float32)\n",
                "bn_var = np.abs(np.random.randn(4).astype(np.float32)) + 0.1\n",
                "bn_gamma = np.random.randn(4).astype(np.float32)\n",
                "bn_beta = np.random.randn(4).astype(np.float32)\n",
                "\n",
                "# Fold BN into conv\n",
                "folded_weight, folded_bias = fold_bn_into_conv(\n",
                "    weight, bias, bn_mean, bn_var, bn_gamma, bn_beta\n",
                ")\n",
                "\n",
                "print(f\"Original weight shape: {weight.shape}\")\n",
                "print(f\"Folded weight shape: {folded_weight.shape}\")\n",
                "print(f\"Original bias shape: {bias.shape}\")\n",
                "print(f\"Folded bias shape: {folded_bias.shape}\")\n",
                "print(\"BN folding successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Run All Tests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run pytest for Triton integration\n",
                "!python -m pytest tests/test_triton_integration.py -v --tb=short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run pytest for QAT\n",
                "!python -m pytest tests/test_qat.py -v --tb=short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run pytest for Triton backend\n",
                "!python -m pytest tests/test_triton_backend.py -v --tb=short"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. QAT Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run QAT benchmark\n",
                "!python benchmarks/qat_benchmark.py --model resnet50 --iterations 50"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run BERT benchmark\n",
                "!python benchmarks/qat_benchmark.py --model bert-base --iterations 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "All tests completed! Check the outputs above for:\n",
                "- Triton Client: Mock inference working\n",
                "- Load Testing: Throughput and latency metrics\n",
                "- QAT: Quantization error bounds\n",
                "- BN Folding: Weight transformation\n",
                "- Full test suite: pytest results"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}