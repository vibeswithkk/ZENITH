# ZENITH GPU Benchmark Report

**Date:** 17 December 2025  
**Environment:** Google Colab  
**GPU:** NVIDIA Tesla T4 (16GB VRAM)  
**CUDA:** 12.6  
**Model:** ResNet-50 (25.6M parameters)  

---

## Summary

| Metric | Value |
|--------|-------|
| Peak Throughput | **377.4 img/sec** |
| Optimal Batch Size | **64** |
| Best Latency | **6.67ms** (batch=1) |
| Peak Memory | **5.4 GB** |

---

## Batch Size Scaling

### Small Batches (CIFAR-10, 224x224)

| Batch | Latency (ms) | Throughput (img/s) | Efficiency |
|-------|--------------|--------------------|-----------:|
| 1 | 6.67 | 150.0 | 1.0x |
| 4 | 12.83 | 311.7 | 2.1x |
| 8 | 24.12 | 331.7 | 2.2x |
| 16 | 42.91 | 372.9 | 2.5x |
| 32 | 82.34 | 388.6 | 2.6x |
| **64** | **169.56** | **377.4** | **2.5x** |

### Large Batches

| Batch | Latency (ms) | Throughput (img/s) | Memory (MB) |
|-------|--------------|--------------------|-----------:|
| 64 | 169.56 | 377.4 | - |
| 128 | 340.89 | 375.5 | - |
| 256 | 707.57 | 361.8 | - |
| 512 | 1425.73 | 359.1 | 5499 |

---

## Model Comparison (batch=1)

| Model | Latency (ms) | Throughput (img/s) |
|-------|--------------|-------------------:|
| ResNet-18 | 3.41 | 293.5 |
| MobileNet-V2 | 4.63 | 215.8 |
| **ResNet-50** | **5.95** | **168.0** |
| EfficientNet-B0 | 7.49 | 133.6 |

---

## Analysis

### Optimal Configuration
- **Batch 64** yields best throughput (377 img/sec)
- Larger batches show diminishing returns due to memory bandwidth
- T4 Tensor Cores utilized via cuDNN implicit calls

### Memory Efficiency
- Peak: 5.4GB / 16GB (34% utilization)
- Room for larger models or multi-model serving

### Recommendations
1. Use batch size 32-64 for optimal throughput
2. Use batch size 1-4 for low-latency applications
3. FP16 inference can double throughput on T4

---

## Hardware Specifications

```
GPU: Tesla T4
Architecture: Turing (SM 7.5)
CUDA Cores: 2560
Tensor Cores: 320
Memory: 16 GB GDDR6
Bandwidth: 320 GB/s
TDP: 70W
```

---

*Generated by Zenith Benchmark Suite*
